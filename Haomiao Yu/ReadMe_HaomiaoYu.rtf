{\rtf1\ansi\ansicpg936\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red33\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c100000\c100000;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 In this individual part, GBDT is used for feature selection.\
\
1. Run DataPreprocessing.py to get the clean data to feed in Gradient Boosting Classifier.\
\
2. Run GBDTLR.py  to get important features and train Logistic Regression Classifier.\
\
3. optimalGBDTLR.py to get the tuned parameters.\
\
4. two Jupyter notebooks to compare results: CTR Estimator(GBDT+LR)-with tuned parameters.ipynb, CTR Estimator(GBDT+LR).ipynb\
\
Dataset: the dataset of this task can be downloaded from https://drive.google.com/file/d/0B73mmT9K2b4EZkZacFVBRDJtdzQ/view
\f1 \cf2 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf3 \
}